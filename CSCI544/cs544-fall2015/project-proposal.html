<html>
<head>
<title>CSCI 544 Applied NLP: Proposing a Group Project</title>
</head>
<body>
<h1>CSCI 544 Applied NLP: Proposing a Group Project</h1>
<h2>Due Date: November 19, 2015, (10:59 AM PST)</h2>

<p>
We will try to comment on proposals submitted before November 6
by the following week. Submitting later may delay approval.
Failure to submit the proposal by the due date (November 19, 10:59 AM PST)
will result in zero credit for both the project and assignment 4 (because
assignment 4 is closely related to the project).
</p>

<p>
<a href="https://usc.qualtrics.com/SE/?SID=SV_5iPxmpgdSaiGp5X"><h2>Online proposal submission.</h2></a>
</p>


<h2>Help in picking a topic</h2> 

<h3>Domain adaptation</h3>

<p>
Domain adaptation is a topic that can be explored in a variety of NLP
tasks.  For many of these tasks, there are large corpora and software
tools trained on these corpora. However, performance of the tools may
drop when used in domains different from the training corpus. The idea
of domain adaptation is to annotate a small amount of training data in
the new domain and create a model based on both the large
out-of-domain corpus and the small in-domain corpus. This can be
applied to NLP tasks such as part of speech tagging, named entity
recognition and parsing.
</p>
<ul>
<li>D. McClosky, E. Charniak and M. Johnson. (2010). <a href="http://nlp.stanford.edu/pubs/dmcc-naacl-2010.pdf">Automatic domain adaptation for parsing.</a> NAACL.</li>
<li>H. Daume III. (2007). <a href="http://www.umiacs.umd.edu/~hal/docs/daume07easyadapt.pdf">Frustratingly easy domain adaptation.</a> ACL.</li>
</ul>


<h3>Speech recognition / speech synthesis topics</h3>

<ul>
<li>Build a limited-domain speech recognizer. You may use out-of-the-box acoustic models, or adapt out-of-the-box acoustic models to a particular speaker. In the latter case you will have a speaker-dependent speech recognizer. You can build domain-specific language models using one of the language modeling toolkits mentioned below.</li>
<li>Build a grapheme to phoneme converter. The input will be a word and the output a sequence of phonemes. You may train and test your model using a pronunciation dictionary, e.g., <a href="http://www.speech.cs.cmu.edu/cgi-bin/cmudict">the CMU pronouncing dictionary.</a></li>
<li>Speech recognition error simulation.</li>
</ul>

<h3>NLU topics</h3>

<ul>
<li><a href="http://aclweb.org/aclwiki/index.php?title=Multiword_Expressions">Recognition of multiword expressions</a> such as compound nouns, proper names, and idioms.</li>
<li>Word sense disambiguation.</li>
<li>Unsupervised learning of lexical semantics.</li>
<li>Learn a probabilistic context-free grammar from a corpus.</li>
<li>Build a limited-domain NLU system using a parser.</li>
<li>Semantic role labeling.</li>
<li>Automatically grade student answers.</li>
<li>Detection of grammatical errors, e.g., wrong prepositions.</li>
</ul>

<h3>Discourse topics</h3>

<ul>
<li>Coreference resolution.</li>
<li>Information extraction.</li>
<li>Discourse segmentation.</li>
<li>Discourse parsing.</li>
<li>Build a simple natural language generation system.</li>
<li>Build a simple summarization system.</li>
</ul>

<h3>Dialogue topics</h3>

<ul>
<li>Build a limited-domain goal-oriented dialogue system.</li>
<li>Build a simple chat-oriented dialogue system.</li>
<li>Develop dialogue management strategies using reinforcement learning.</li>
</ul>

<h2>Help in finding data</h2>

<ul>
<li><a href="http://www.nltk.org/nltk_data/">NLTK data</a>: a large repository of many kinds of data.</li>
<li><a href="http://www-nlpir.nist.gov/related_projects/muc/muc_data/muc_data_index.html">Message Understanding Conferences 3 and 4</a> (information extraction, named entity recognition, coreference resolution).</li>
<li><a href="https://framenet.icsi.berkeley.edu/fndrupal/">FrameNet</a> (Semantic Role information).</li>
<li><a href="https://verbs.colorado.edu/propbank/">PropBank / AMR info.</a></li>
<li><a href="http://www.clips.uantwerpen.be/conll2000/">Computational Natural Language Learning conference shared tasks:</a></li>
<ul>
<li>1999 and 2000: chunking;</li>
<li>2001: clause identification (good for discourse parsing);</li>
<li>2002 and 2003: named entity recognition;</li>
<li>2004 and 2005: semantic role labeling;</li>
<li>2008: syntactic and semantic dependencies.</li>
</ul>
<li>SemEval shared tasks:</li>
<ul>
<li><a href="http://aclweb.org/aclwiki/index.php?title=SemEval_3">2012-2015;</a></li>
<li><a href="http://alt.qcri.org/semeval2016/">2016.</a></li>
</ul>
<li>Dialogue State Tracking Challenges:</li>
<ul>
<li><a href="http://research.microsoft.com/en-us/events/dstc/">Dialogue State Tracking Challenge;</a></li>
<li><a href="http://camdial.org/~mh521/dstc/">Dialogue State Tracking Challenge 2 & 3;</a></li>
<li><a href="http://www.colips.org/workshop/dstc4/">Dialogue State Tracking Challenge 4.</a></li>
</ul>
</ul>

<h2>Useful tools and resources for speech recognition</h2>

<ul>
<li><a href="http://cmusphinx.sourceforge.net/wiki/download">CMU Sphinx and PocketSphinx.</a></li>
<li><a href="http://htk.eng.cam.ac.uk/">HTK Speech Recognition Toolkit.</a></li>
<li><a href="http://julius.osdn.jp/en_index.php">Open-Source Large Vocabulary Continuous Speech Recognition Engine Julius.</a></li>
<li><a href="http://kaldi.sourceforge.net/about.html">Kaldi.</a></li>
<li><a href="http://www.keithv.com/software/">Trained acoustic models.</a></li>
</ul>

<h2>Useful tools and resources for language modeling</h2>

<ul>
<li><a href="http://www.speech.cs.cmu.edu/SLM/toolkit.html">CMU-Cambridge Statistical Language Modeling Toolkit.</a></li>
<li><a href="http://www.speech.sri.com/projects/srilm/">SRI Language Modeling Toolkit.</a></li>
<li><a href="https://code.google.com/p/mitlm/">MIT Language Modeling Toolkit.</a></li>
<li><a href="http://www.openfst.org/twiki/bin/view/Contrib/GrmLibrary">GRM Library.</a></li>
<li><a href="http://www.keithv.com/software/">Trained language models.</a></li>
</ul>

<h2>Useful tools and resources for speech synthesis</h2>

<ul>
<li><a href="http://www.cstr.ed.ac.uk/projects/festival/">Festival Speech Synthesis System.</a></li>
<li><a href="http://festvox.org/flite/">CMU Flite (festival-lite).</a></li>
<li><a href="http://festvox.org/cmu_arctic/">CMU_ARCTIC speech synthesis databases.</a></li>
<li><a href="http://hts.sp.nitech.ac.jp/">HMM-based Speech Synthesis System (HTS).</a></li>
<li><a href="http://mary.dfki.de/">MARY Text-to-Speech System (MaryTTS).</a></li>
</ul>

<h2>Useful tools for building dialogue systems</h2>

<ul>
<li><a href="https://vhtoolkit.ict.usc.edu/">Virtual Human Toolkit.</a></li>
<li><a href="http://www.opendial-toolkit.net/">OpenDial.</a></li>
</ul>

</body>
</html>
